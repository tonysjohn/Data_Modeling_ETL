*Disclaimer: This project is part of Udacity Data Engineering Nanodegree*

## Introduction
The objective of this project is to create and deploy a data model for a fictional company Sparkify for its new music streaming application.

This involves proportioning a database schema, creating necessary tables and deploying a ETL pipeline to push data to Data Store. The solutioning is done with PostgreSQL database and ETL pipeline is built using Python and SQL. The input data are in JSON logs and are comprised of user activity logs and metadata about songs. Finally, the database is tested using basic queries to compare with expected results.

## Project Datasets
#### Song Metadata Dataset
The first dataset is a subset of real data from the Million Song Dataset. Each file is in JSON format and contains metadata about a song and the artist of that song. The files are partitioned by the first three letters of each song's track ID. For example, here are filepaths to two files in this dataset.

song_data/A/B/C/TRABCEI128F424C983.json  
song_data/A/A/B/TRAABJL12903CDCF1A.json

And below is an example of what a single song file, TRAABJL12903CDCF1A.json, looks like.

`{"num_songs": 1, "artist_id": "ARJIE2Y1187B994AB7", "artist_latitude": null, "artist_longitude": null, "artist_location": "", "artist_name": "Line Renaud", "song_id": "SOUPIRU12A6D4FA1E1", "title": "Der Kleine Dompfaff", "duration": 152.92036, "year": 0}`

#### User Activity Log Dataset
The second dataset consists of log files in JSON format generated by this event simulator based on the songs in the dataset above. These simulate activity logs from a music streaming app based on specified configurations.

The log files in the dataset you'll be working with are partitioned by year and month. For example, here are filepaths to two files in this dataset.

log_data/2018/11/2018-11-12-events.json  
log_data/2018/11/2018-11-13-events.json

And below is an example of what the data in a log file, 2018-11-12-events.json, looks like.

![Log Data sample](/images/log-data.png)

## Schema for Song Play Analysis
Using the song and log datasets, you'll need to create a star schema optimized for queries on song play analysis. This includes the following tables.

![Schema Diagram](/images/schema.PNG)

## ETL Process

etl.py file is used to implement the ETL process
1. Data from __Song Metadata__ files are fed to __Songs__ and __Artists__ tables
2. Data from __User Avity log__ files are fed to populate __Songplays__, __Users__ and __Time__ tables

Required SQL queries are saved in sql_queries.py file.


